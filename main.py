import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# 1. ë°ì´í„° ìƒì„± (ê°€ìƒì˜ ë°ì´í„°)
np.random.seed(42)
dates = pd.date_range(start="2020-01-01", periods=100, freq='W')
marketing_spend = np.random.normal(loc=5000, scale=1000, size=100)  # ë§ˆì¼€íŒ… ì§€ì¶œ
price_index = np.random.normal(loc=100, scale=10, size=100)           # ê°€ê²© ì§€ìˆ˜

# ë§¤ì¶œì€ ë§ˆì¼€íŒ… ì§€ì¶œê³¼ ê°€ê²© ì§€ìˆ˜ì— ì˜í–¥ì„ ë°›ëŠ”ë‹¤ê³  ê°€ì •í•˜ê³  ìƒì„±
sales = 20000 + 3 * marketing_spend - 150 * price_index + np.random.normal(loc=0, scale=3000, size=100)

# ë°ì´í„°í”„ë ˆì„ ìƒì„±
data = pd.DataFrame({
    "Date": dates,
    "MarketingSpend": marketing_spend,
    "PriceIndex": price_index,
    "Sales": sales
})
data.set_index("Date", inplace=True)

# 2. íŠ¹ì§•(feature)ê³¼ íƒ€ê¹ƒ(target) ë³€ìˆ˜ ì„¤ì •
X = data[["MarketingSpend", "PriceIndex"]]
y = data["Sales"]

# 3. í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. íšŒê·€ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ

# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# ì„ í˜• íšŒê·€ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)  # íšŒê·€ ëª¨ë¸ì´ë¯€ë¡œ ì—°ì†í˜• ê°’ ì‚¬ìš© ê°€ëŠ¥

# XGBoost ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
xgb.fit(X_train, y_train)

# SVR(ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  íšŒê·€) ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
svr = SVR(kernel="rbf", C=100, gamma=0.1)
svr.fit(X_train, y_train)

# K-ìµœê·¼ì ‘ ì´ì›ƒ íšŒê·€ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(X_train, y_train)

# 5. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ë° í‰ê°€
y_pred_random_forest = rf.predict(X_test)
mse = mean_squared_error(y_test, y_pred_random_forest)
print("Random Forest MSE:", mse)

y_pred_lin_reg = lin_reg.predict(X_test)
mse_lin_reg = mean_squared_error(y_test, y_pred_lin_reg)
print("Linear Regression MSE:", mse_lin_reg)

y_pred_xgb = xgb.predict(X_test)
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
print("XGBoost MSE:", mse_xgb)

y_pred_svr = svr.predict(X_test)
mse_svr = mean_squared_error(y_test, y_pred_svr)
print("SVM (SVR) MSE:", mse_svr)

y_pred_knn = knn.predict(X_test)
mse_knn = mean_squared_error(y_test, y_pred_knn)
print("KNN Regression MSE:", mse_knn)

# 6. ì‹¤ì œ ë§¤ì¶œê³¼ ì˜ˆì¸¡ ë§¤ì¶œ ì‹œê°í™”
plt.rc('font', family='Malgun Gothic')
plt.figure(figsize=(12,6))
plt.scatter(y_test, y_pred_random_forest, label="RandomForest", color='blue', edgecolor='k', alpha=0.7)
plt.scatter(y_test, y_pred_xgb, label="XGBoost", color='purple', edgecolor='k', alpha=0.6)
plt.scatter(y_test, y_pred_svr, label="SVR", color='yellow', edgecolor='k', alpha=0.6)
plt.scatter(y_test, y_pred_knn, label="KNN", color='red', edgecolor='k', alpha=0.6)

plt.xlabel("ì‹¤ì œ ë§¤ì¶œ")
plt.ylabel("ì˜ˆì¸¡ ë§¤ì¶œ")
plt.title("ì‹¤ì œ ë§¤ì¶œ vs ì˜ˆì¸¡ ë§¤ì¶œ")
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')  # y=x ì„ 
plt.show()

print("\nğŸ“Š ëª¨ë¸ë³„ í‰ê·  ì œê³± ì˜¤ì°¨ (MSE) ë¹„êµ")
print("Linear Regression MSE:", mse_lin_reg)
print(f"ğŸ“Œ XGBoost: {mse_xgb:.2f}")
print(f"ğŸ“Œ SVM (SVR): {mse_svr:.2f}")
print(f"ğŸ“Œ KNN: {mse_knn:.2f}")